{
  
    
        "post0": {
            "title": "Building a model to predict IPL match outcomes",
            "content": "App Link with final predictions - https://share.streamlit.io/arpitsolanki/ipl-prediction-engine/main/app.py . Code -https://github.com/arpitsolanki/IPL-Prediction-Engine . Background . Over the last few months I’ve been trying to combine my two passions - sports &amp; data analytics. It all started with using analytics to get better at Fantasy League for Football, I also recently participated in annual Kaggle competition for predicting outcomes of NCAA matches. While I enjoyed both those projects, I found that my lack of knowledge for Football &amp; Basketball limited my abilities to come up with good features &amp; models to some extent. Therefore I decided to pick up Cricket, a sport which I understand really well and have been following for a long time. . Cricket traditionally isn’t a sport which has been known for widespread usage of data to inform tactics &amp; team selection, at least not to the extent of some other sports like Baseball &amp; Football. However with the growing popularity of T20 over the last 10 years, things have been changing very rapidly in Cricket as well, with teams employing performance analysts &amp; using data to get any possible edge over the opposition. This has spilled over to cricket broadcasts &amp; journalism as well, with commentators trying to bring in more visualizations &amp; journalists using data to create stories around their articles. A great example of this is Jarrod Kimber, who uses a lot of analytics in his video blogs to deep dive into matches &amp; explain why teams performed in a certain manner. I’d been watching all of this very closely over the years &amp; decided to get my hands dirty &amp; combine my love for the sport of cricket and my skills as a data analyst to create a project around predicting match outcomes for IPL matches using data analytics. . Why IPL is a difficult tournament to predict accurately? . I did check out a few solutions available on the internet predicting match outcomes, but they all had low accuracy scores, sometimes worse than a coin toss. I think this could be due to the following reasons - . Upsets are more likely in T20 than any other cricket format. In cricket or any other sport, the longer the match goes, the stronger team has much higher chance of overcoming poor passages of play and win the game, but since T20 cricket is just 120 balls per innings, few moments of individual brilliances can change outcomes of games. | IPL teams have a fixed purse amount to spend on players, which ensures a level playing field. The difference in quality in best &amp; worst teams isn’t as high as in some other sports like EPL, NBA etc. | The format for tournament isn’t consistent - squads get changed every few years, gets played outside India every now and then, teams keep getting added or banned. This makes it difficult to get high volume of high quality data &amp; there’s too much noise added due to above factors | As I mentioned earlier, except for a few there aren’t many teams which have consistently dominated the IPL over a long time. A team having a good season can suddenly become poor the next season. The above chart shows the percentage of matches won by IPL teams over different seasons. There aren’t too many relatively straight lines in the chart above - win rates for teams wildly fluctuates from one season to the other. There are two teams which have had longer successful spells - Mumbai Indians &amp; Chennai Super Kings, but even they’ve had poor run of seasons every now and then. | Gathering Data . I had initially thought that getting access to good quality data for IPL matches would be a challenge, but a few google searches helped me discover cricsheet.org - absolute gem of a website when it comes to cricket data. It tracks data for all major domestic &amp; international competitions going back several years. The dataset available for IPL is fairly granular - ball by ball data for all the IPL matches that have happened so far. This is how the data looks like - . enter image description here . The data is available for all the matches, tracking information around venue, batsman, bowler, extras, dismissals etc. However, it does require some amount of cleaning &amp; wrangling to get it into a format ready for making predictions. . Data Preparation . Although the data is available in a reasonably clean format, there are still some operations that need to be performed to get the data in a desired format - . Ensure team &amp; stadium across season are consistent. For ex. Hyderabad team shows up as Deccan Chargers, Sunrisers Hyderabad across multiple seasons. Ensuring that such instances are treated as same across seasons | Roll-up the ball level data to match by match data, with clear winner being identified for each match. | Feature Engineering . As with any modelling problem, domain knowledge is very important to come up with good features relevant to the problem statement. Very often the quality of data is just as important as the choice of the model for making predictions. Based on my experience of watching cricket broadcasts over the years, I came up with a list of factors which I think play a role in determining match outcomes. Exploratory analysis of data on these factors along with several iterations during the model building stage will help us select the optimal set of features which maximizes prediction accuracy. Here are the categories of features I came up with intuitively - . Venue Stats . Home/Away fixture - Unlike football &amp; some other sports, pitch conditions play a huge role in determining the outcome of the match. Teams create squads to suit their home ground pitch conditions - for ex. Chennai going spin heavy to suit spinning pitches at Chepauk. | Venue Win Rates - As some seasons are played at neutral venues, its good to keep a track of a team’s performance at every individual venue | Runs &amp; Wicket Stats . Powerplay Batting &amp; Bowling Stats - Number of wickets &amp; runs scored on average while batting &amp; bowling during powerplay | Innings Batting &amp; Bowling Stats - Number of wickets taken &amp; runs scored on average while batting &amp; bowling during the entire innings | Win Rate Stats . Team Overall Win Rates - Even though we saw that a team’s win rate in a season can fluctuate a lot over multiple seasons, its still a good metric to separate the likes of MI &amp; CSK | Head2Head - Head to head records of teams against each other | Season Performance Stats - Team’s position on points table &amp; number of matches won in a season is a good indicator of recent form and could be useful for predicting the winner. For ex. you would expect a team at the top of the table to beat the team at the bottom of the table most times during a season. | Let’s start diving deep into some of these feature groups and look at which ones correlate with a team’s win rate. . Venue Stats . . As you can see above, most teams seem to do well in their home conditions compared to away grounds. Teams play at least half of their matches at their home ground every season. Pitch characteristics &amp; ground sizes vary a lot across India, with some pitches like Chennai being spin bowler friendly while others like Bangalore being a batting paradise. Teams therefore build their squad to best suit their home ground conditions which gives them an advantage over visiting teams. Also home support is a big factor as all IPL games are well attended and fan bases are quite strong. . Rajasthan &amp; Chennai both win almost 70% of their matches on their home grounds. No team other than Mumbai &amp; Chennai has a win_rate of more than 50% on away grounds. This versatility across conditions is probably the reason why both Mumbai &amp; Chennai are the strongest teams in the IPL. Let’s also look at distribution of win rates across different grounds to see how much an individual team’s performance varies across grounds - . . As you can see in the chart above, team’s win rate at different venues fluctuates quite a bit. The violins above show that even within away venues there is a huge variation in win rates for teams. This proves the point that pitch &amp; ground conditions play a huge role in deciding match outcomes and should not be ignored while creating the model. . Batting &amp; Bowling Stats . The above scatter plot shows us a scatter plot distribution between win rates for teams &amp; their average bowling &amp; batting stats for powerplay &amp; innings. For some of these stats like mean runs scored while batting first have a correlation pattern with win rate, some others like numbers of runs scored during powerplay while batting first don’t show any relationship with the win rates. A study of these scatter plots will help us understand which variables correlate with win rate &amp; will help us in feature selection feature engineering stage of the exercise. . Win Rate Stats We’re looking at multiple win rate stats like head to head records of teams against each other, overall win rates since the beginning of the IPL, total number of wins in the ongoing season. Let’s take a look at one feature - difference in number of wins for the ongoing season. . . As we can see above, current form in the season plays an important role in determining match outcomes. Teams that have won a significantly higher number of matches compared to the opposition in the season tend to win more often. . Model Design &amp; Development . . Summarizing the image above - . Model development - Happens one per season using training data as data of all the previous seasons | Test Data Update - Happens once every week taking into account change in team’s batting &amp; bowling stats as well as current season’s performance. This test data is used to make predictions every week. | The aim of the model is to predict the winning team for every match. We use tree based ensemble Random Forest for making our predictions. After several iterations of model hyperparameter tuning &amp; feature selection, here is the final feature importance plot we got for our model. . . Current season form is the most important feature, followed by difference in number of mean runs scored along with overall win rates in the IPL. Since we only have about 500 data points, its good to restrict depth of trees &amp; the number of features going into the model to avoid overfitting. . We also tested out the model for different seasons, looking to get an understanding of the average accuracy of the model over multiple seasons. As mentioned above, for making predictions for a season, we train the model with data up until the last season and make predictions on the current season. Using this method the general accuracy of the model lies in the range of 65%-70%, though it fell down to 61% for the 2018 season. . . Generally you would expect model to get better with every passing year due to availability of more data, but that isn’t the case with IPL due to the reasons mentioned earlier -complete changes in squads due to mega auctions, tournament shifting to neutral venues etc. . Alternative approaches . While this model gives us reasonable accuracy, there is still a lot of scope for improvement. We did not consider toss outcomes, match importance for teams, day/night status and squad strength based on players involved in the match during our prediction. Adding these &amp; other features could potentially improve the model accuracy. . While researching for methods to make predictions on sports outcomes, I also came across the fivethirtyeight.com method to create Elo ratings for teams based on squad strength and then run Monte Carlo simulations thousands of times and predict the outcomes of matches &amp; seasons. They’ve used this approach number of times for sports like Football, Basketball, Baseball etc. I’ve found it to be fascinating and will be looking to try that out for upcoming seasons &amp; tournaments as well. . Final Comments . This was a fun exercise and took me about two weekends to complete the entire process from data gathering, manipulation to model building. The final predictions have been made available on a Streamlit app. Code is available here . Hope you guys enjoyed reading it. Please feel free to leave your feedback in comments. . PS - Unfortunately the IPL season had to be postponed due to Covid situation in India, but this was a fun project &amp; acted as a good starting point for me to use data for cricket. Will look to build on my work again when normalcy is restored to life &amp; cricket. .",
            "url": "https://arpitsolanki.github.io/blog/2021/04/15/Building-a-model-to-predict-IPL-match-outcomes.html",
            "relUrl": "/2021/04/15/Building-a-model-to-predict-IPL-match-outcomes.html",
            "date": " • Apr 15, 2021"
        }
        
    
  
    
        ,"post1": {
            "title": "Kaggle BCG - COVID-19 AI Challenge - First Prize Submission",
            "content": "Background . 2020 was a difficult year for everyone around the world due to the Coronavirus pandemic. During the initial months of the pandemic we knew very little about the virus,how it spread and the potential treatments that could be used against it. We saw reports of medical infrastructure getting overburdened and high fatality rates across the globe due to lack of proper treatments for the virus. As time went on we kept learning more about the virus &amp; the entire scientific &amp; medical community got together to find ways of overcoming the virus. Among many things that came out, ones that I found particularly interesting were articles being published around negative correlation between BCG vaccination prevalence within a country &amp; fatality rates from the virus. At the same time University of Ottawa &amp; Estafet launched a hackathon on Kaggle to study this problem statement in more detail. The notebook below includes code for my submission for the hackathon, which won the first prize. .",
            "url": "https://arpitsolanki.github.io/blog/2021/03/01/BCG-Covid19-AI-Challenge.html",
            "relUrl": "/2021/03/01/BCG-Covid19-AI-Challenge.html",
            "date": " • Mar 1, 2021"
        }
        
    
  
    
        ,"post2": {
            "title": "Using ML to win FPL",
            "content": "Using ML to get better at FPL . Background . 2020 was a particularly difficult year for everyone, with so much suffering around the world &amp; life becoming still for everyone stuck in their homes due to lockdowns. As a sports lover, I found it particularly difficult to get used to a life without any live sport. Summers in India are particularly packed with excitement of home test series at the start of the year and then IPL for the months of April &amp; May. Without access to any live sport, I turned to OTT platforms and started watching documentaries around football teams like Man City, Leeds United, Tottenham Hotspur, Sunderland etc. I finished all of them in no time and though I’ve been a cricket fan most of my life &amp; watching football for me meant only international competitions like World Cup &amp; Euros, I started getting attracted to club football. . As the spread of Covid started reducing around the world, football was the first sport to break through the shackles &amp; premier league football resumed around the month of July. I got hooked to the sport and at the same time also got introduced to the world of Fantasy Football. I decided to give it a shot with new season beginning in September. Because I was still very new to football my knowledge around players capabilities in PL was still very limited, that led me to make several poor decisions. I also found myself getting biased around clubs that I liked &amp; filling squad with players from those clubs. This led to a poor showing after the first few gameweeks of FPL. I decided to put my skillset of data analysis to work and use it to compensate for my lack of understanding of PL and understand how different players compare against each other &amp; make transfer decisions backed by data. . Gathering Data . Following are the list of data sources used by me for the analysis . Vaastav FPL Github - This I think is the best available data repository for FPL containing historical data around players &amp; team performances in FPL going back several years and gets refreshed on a weekly basis. Data is available here | FPL API - I used FPL API to get info around upcoming fixtures &amp; status of players fitness for a gameweek. Details around how to access the API can be found here | FivethirtyEight scores prediction - I really like Nate Silver’s fivethirtyeight.com]which uses analytics &amp; data science to predict outcomes of several real life events. They also make predictions around expected score for games in PL as well. I use this dataset capture level of difficulty of a fixture &amp; scores prediction | Data Overview . Our base dataset for this analysis is the Github repository mentioned above. It contains various data points around a player’s performance in a particular match as shown below - . . We combine the base datasets with additional data points from the FPL API &amp; Fivethirtyeight datasets. Once we have the data ready, the first thing we do is to look at distribution of points scored by players during a game week. As the chart below suggests, huge majority of players score less than or equal to 2 points in a game week. Events providing returns like assists, goals &amp; clean sheets are quite rare. High number of players scoring zeros could be attributed to the fact that all premier league have big squads of around 25 players and only about 12-13 of them feature in a game. Since the distribution of points scored by players for more than 2 points is quite scattered, its quite difficult to actually predict the exact number of points scored by a player. . Let’s now look at how the proportion of blanking(&lt;=2 pts) and not blanking(2+points) looks by player position. Goalkeepers are most likely to blank based on the chart below, seems logical as well since only way GKs generally gain points is by maintaining clean sheets. For every other position, the proportions are quite similar. . After taking a look at the above data points, I decided that it will be a better idea to build a classification model rather than a regression model for this exercise. The objective of the model would be to identify players who are most likely to score 2+points in a week. Since most players score less than 2 points in a week, this would be an example of imbalanced classification problem. We’ll be building tree based classifiers for this problem. . Feature Engineering . Quality of predictions for any model is directly correlated to the quality of features being fed into the model. I found the overall quality of data to be very rich &amp; clean for this project, therefore lot of variables available in the raw datasets can directly be used as features. On top of that I added several features on my end to capture form &amp; opponent strengths into the model. After going through several iterations of model training on added features, here are the list of features I came up with - . Player Performance . Influence, Creativity &amp; Threat metrics | Rolling average of points scored during last four weeks | Position of a player | Player’s contribution to team’s total points | Rolling average of minutes played during last four weeks | Goals scored, assists &amp; clean sheets kept | Yellow &amp; Red Cards | Number of incoming transfers by FPL managers during a game week | . Team Performance . Diff. between team &amp; opponent’s position in the points table | Team’s form over last four weeks | Home or away fixture | Projected scores from fivethirtyeight | Total points scored by all players in the team | Penetrations into opponent’s box &amp; number of penetrations allowed | . Model Design . My workflow has been designed in such a way that it uses historical data for the entire season until the latest gameweek for training the model &amp; then makes prediction for the upcoming week. Predictions includes list of 11 players who are most likely to score more than 2 points during the gameweek. The project is deployed as a pipeline that runs every week and uses historical data till the latest game week and makes prediction for the upcoming game week. . Model Development . As seen in the data earlier majority of the players during a particular gameweek tend to blank(score less than or equal to 2 points for appearance). Since football is a low scoring sport &amp; events like goals etc. can be quite random, it is very hard to predict the exact number of points scored by a player during a game week. Therefore I turned this into a 2 class classification problem where i’m just trying to predict if a player would blank in a particular gameweek or score more than 2+ points. . I decided to train tree based ensemble models using Random Forests &amp; XGBoost and used a weighted average of the predictions used by both the models. The final output of model is a dataset with probability of each player not blanking during the upcoming game week. Here is the feature importance plot for the random forest model - . As we all know the 2020-21 season been a pretty weird one with teams going through runs of good &amp; bad forms. The model seems to recognize that as well &amp; the features with rolling average of last four weeks on points scored, ICT index etc. tend to have a lot of importance. This model in particular tends to answer the classic conundrum of FPL managers - form vs fixtures in favor of form. . This model had an overall accuracy of 78%, but given that this is an imbalanced classification problem and we’re interested in accurately identifying top 11 players who are likely to score, we’re more interested in the true positive rate of the model. . . . The above charts show us that predicted probability distribution is heavily skewed to the left and very few players have predicted probability over 0.5. The AUC for ROC curve is 0.75 and the True Positive Rate is 70%. This is not bad for an initial model but definitely room for improvement in future iterations. . Output . The final output of the model is a list of 11 players who are most likely to score 2+points during the upcoming game week. The workflow runs for every game week and the output predictions are available on the Streamlit website created here. . I also look at points scored in previous game weeks by my team vs the actual dream team for the week &amp; average score for the game week. So far we can say that the team predicted by the model is doing slightly better than the average human on points scored every game week. Looking at the predictions for the six game weeks the model has been running, model team scored 249 points vs sum of average score of 239 pts. . Hope is that model will continue to improve in its predictions through the season as it has access to higher volume of training data. . Code for the entire project can be found here . Next Steps &amp; Improvement . This entire project was taken up by me as a Christmas project to understand PL football better &amp; learn to use Streamlit for dashboarding. During the development of project I identified a few things that could be better - . Gather different metrics for attacking &amp; defensive footballers and train different models for each | Use Linear Programming to optimize the maximum points from the predicted team while ensuring that team budget doesn’t cross 100M pounds. I’ll be looking to work further on this &amp; hopefully improve the performance of this model. |",
            "url": "https://arpitsolanki.github.io/blog/2021/02/06/Using-ML-to-win-FPL.html",
            "relUrl": "/2021/02/06/Using-ML-to-win-FPL.html",
            "date": " • Feb 6, 2021"
        }
        
    
  
    
        ,"post3": {
            "title": "Fastpages Notebook Blog Post",
            "content": "About . This notebook is a demonstration of some of capabilities of fastpages with notebooks. . With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! . Front Matter . The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this: . # &quot;My Title&quot; &gt; &quot;Awesome summary&quot; - toc:true- branch: master - badges: true - comments: true - author: Hamel Husain &amp; Jeremy Howard - categories: [fastpages, jupyter] . Setting toc: true will automatically generate a table of contents | Setting badges: true will automatically include GitHub and Google Colab links to your notebook. | Setting comments: true will enable commenting on your blog post, powered by utterances. | . The title and description need to be enclosed in double quotes only if they include special characters such as a colon. More details and options for front matter can be viewed on the front matter section of the README. . Markdown Shortcuts . A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. . A #hide_input comment at the top of any code cell will only hide the input of that cell. . The comment #hide_input was used to hide the code that produced this. . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . import pandas as pd import altair as alt . . put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it: . cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . place a #collapse-output flag at the top of any cell if you want to put the output under a collapsable element that is closed by default, but give the reader the option to open it: . print(&#39;The comment #collapse-output was used to collapse the output of this cell by default but you can expand it.&#39;) . The comment #collapse-output was used to collapse the output of this cell by default but you can expand it. . . Interactive Charts With Altair . Charts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook. . Example 1: DropDown . # use specific hard-wired values as the initial selected values selection = alt.selection_single( name=&#39;Select&#39;, fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;], init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;}, bind={&#39;Major_Genre&#39;: alt.binding_select(options=genres), &#39;MPAA_Rating&#39;: alt.binding_radio(options=mpaa)} ) # scatter plot, modify opacity based on selection alt.Chart(df).mark_circle().add_selection( selection ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=&#39;IMDB_Rating:Q&#39;, tooltip=&#39;Title:N&#39;, opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05)) ) . Example 2: Tooltips . alt.Chart(df).mark_circle().add_selection( alt.selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;]) ).encode( alt.X(&#39;Rotten_Tomatoes_Rating&#39;, type=&#39;quantitative&#39;), alt.Y(&#39;IMDB_Rating&#39;, type=&#39;quantitative&#39;, axis=alt.Axis(minExtent=30)), # y=alt.Y(&#39;IMDB_Rating:Q&#39;, ), # use min extent to stabilize axis title placement tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;] ).properties( width=500, height=400 ) . Example 3: More Tooltips . label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=500, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget Distributor MPAA_Rating IMDB_Rating Rotten_Tomatoes_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | Gramercy | R | 6.1 | NaN | . 1 First Love, Last Rites | 10876.0 | 300000.0 | Strand | R | 6.9 | NaN | . 2 I Married a Strange Person | 203134.0 | 250000.0 | Lionsgate | None | 6.8 | NaN | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | Fine Line | None | NaN | 13.0 | . 4 Slam | 1087521.0 | 1000000.0 | Trimark | R | 3.4 | 62.0 | . Images . Local Images . You can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax: . ![](my_icons/fastai_logo.png) . . Remote Images . Remote images can be included with the following markdown syntax: . ![](https://image.flaticon.com/icons/svg/36/36686.svg) . . Animated Gifs . Animated Gifs work, too! . ![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif) . . Captions . You can include captions with markdown images like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Other Elements . GitHub Flavored Emojis . Typing I give this post two :+1:! will render this: . I give this post two :+1:! . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: . Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: . Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: . Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: . Note: Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: . Note: A doc link to an example website: fast.ai should also work fine. . Footnotes . You can have footnotes in notebooks, however the syntax is different compared to markdown documents. This guide provides more detail about this syntax, which looks like this: . For example, here is a footnote {% fn 1 %}. And another {% fn 2 %} {{ &#39;This is the footnote.&#39; | fndetail: 1 }} {{ &#39;This is the other footnote. You can even have a [link](www.github.com)!&#39; | fndetail: 2 }} . For example, here is a footnote 1. . And another 2 . 1. This is the footnote.↩ . 2. This is the other footnote. You can even have a link!↩ .",
            "url": "https://arpitsolanki.github.io/blog/jupyter/2020/02/20/test.html",
            "relUrl": "/jupyter/2020/02/20/test.html",
            "date": " • Feb 20, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "I am an analytics professional based out of Bangalore, India. I have 8+ years of experience working as a Decision Scientist &amp; managing teams of various sizes. My interests include Data Science, Sports &amp; Finance. My posts on this blog mostly includes my projects with an intersection of one of these fields as well as my learnings in the field of Data Science. . You can reach out to me at arpitsolanki14@gmail.com. .",
          "url": "https://arpitsolanki.github.io/blog/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://arpitsolanki.github.io/blog/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}